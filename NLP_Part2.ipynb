{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "da615252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "import textwrap \n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c8ea9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2118429",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\"n/a\", \"na\",\"NA\",\"NaN\", \"--\", \"Not Answer\",\"Not_Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90e9bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Yannis/Desktop/NLP/Suspicious Communication on Social Platforms.csv', na_values = missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff84a08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  tagging\n",
       "0                             Get fucking real dude.        1\n",
       "1   She is as dirty as they come  and that crook ...        1\n",
       "2   why did you fuck it up. I could do it all day...        1\n",
       "3   Dude they dont finish enclosing the fucking s...        1\n",
       "4   WTF are you talking about Men? No men thats n...        1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a89d7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagging</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12179</td>\n",
       "      <td>11861</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7822</td>\n",
       "      <td>2789</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comments                    \n",
       "           count unique     top freq\n",
       "tagging                             \n",
       "0          12179  11861  #NAME?   23\n",
       "1           7822   2789  #NAME?   18"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('tagging').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7000209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_Class = pd.value_counts(df.tagging, sort = True)\n",
    "\n",
    "# Data to Plot\n",
    "labels = '0', '1'\n",
    "sizes = [count_Class[0], count_Class[1]]\n",
    "colors = ['red', 'yellow']\n",
    "explode = (0.1, 0.1)\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, explode = explode, labels = labels, colors = colors,\n",
    "        autopct = '%1.1f%%', shadow = True, startangle = 90)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33a452e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments    0\n",
       "tagging     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363fdfb",
   "metadata": {},
   "source": [
    "### Function that prints features with the highest coefficient values, per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1cc8ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_most_informative_features(clf, vectorizer, \n",
    "                                  label_names, \n",
    "                                  max_number_informative_features):\n",
    "\n",
    "    output = []\n",
    "\n",
    "    \n",
    "    try:\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "        label_index = len(label_names)\n",
    "        \n",
    "        if label_index == 2:\n",
    "            label_index = 1\n",
    "            #print('features for binary classification!')\n",
    "        \n",
    "        for index in range(label_index):\n",
    "            #print(str(index) + label_names[index])\n",
    "            #print('clf.coef_:',len(clf.coef_))\n",
    "            \n",
    "            output.append('\\n' + label_names[index] + ':\\n')\n",
    "            \n",
    "            coefs_with_fns = sorted(zip(clf.coef_[index], feature_names))\n",
    "            \n",
    "            #print(coefs_with_fns)\n",
    "            \n",
    "            threshold = int(max_number_informative_features / 2)\n",
    "\n",
    "            top = zip(coefs_with_fns[:threshold],\n",
    "                      coefs_with_fns[:-(threshold + 1):-1])\n",
    "            \n",
    "            for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "                feat = \"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2)\n",
    "                output.append(feat)\n",
    "            \n",
    "            #print('\\n'.join(output))\n",
    "                \n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        raise \n",
    "        return '\\n'.join(output)\n",
    "\n",
    "    return '\\n'.join(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "54bce955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_categories(dict, value):\n",
    "    \n",
    "    if not value.isdigit():\n",
    "        return None\n",
    "    \n",
    "    for key, val in dict.items():\n",
    "        if val == int(value):\n",
    "            return key\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8183d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comments']\n",
    "y = df['tagging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c23489ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf79f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add lemmatizer\n",
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
    "def LemmaTokenizer(X):\n",
    "    \n",
    "    for comment in X:\n",
    "        doc= nlp(comment)\n",
    "        ' '.join([token.lemma_ for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "42ee2099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 14686)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use lemmaTokenizer within count vectorizer with greater word sequences \n",
    "# tokenizer = LemmaTokenizer(X)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_Trainvec = cv.fit_transform(X_train)\n",
    "X_train.shape\n",
    "X_Trainvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06ce4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Testvec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4a3b934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = pd.read_csv('toxic_reddit_tagged.csv', na_values = missing_values)\n",
    "\n",
    "X_test_red = df_red[\"comments\"]\n",
    "y_test_red = df_red['tagging']\n",
    "\n",
    "X_Testvec_red = cv.transform(X_test_red)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23158a5d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f4347e71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9342666666666667\n",
      "Test 0.8234353129374126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_Trainvec, y_train)\n",
    "lr_score = lr.score(X_Trainvec, y_train)\n",
    "print(\"Train\", lr_score)\n",
    "lr_score = lr.score(X_Testvec, y_test)\n",
    "print( \"Test\",lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c7216c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(X_Testvec)\n",
    "no_of_features = lr.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "978c11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      2859\n",
      "           1       0.82      0.75      0.78      2142\n",
      "\n",
      "    accuracy                           0.82      5001\n",
      "   macro avg       0.82      0.81      0.82      5001\n",
      "weighted avg       0.82      0.82      0.82      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76068b25",
   "metadata": {},
   "source": [
    "### Perform LR for Reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4d3f300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.5655684179281686\n"
     ]
    }
   ],
   "source": [
    "lr_score = lr.score( X_Testvec_red, y_test_red)\n",
    "print( \"Test\",lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0f19c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.69     15022\n",
      "           1       0.16      0.71      0.26      1823\n",
      "\n",
      "    accuracy                           0.57     16845\n",
      "   macro avg       0.55      0.63      0.48     16845\n",
      "weighted avg       0.85      0.57      0.65     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr.predict(X_Testvec_red)\n",
    "print(classification_report(pred,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78871cbc",
   "metadata": {},
   "source": [
    "**In the above model, we used unigrams (single words) only. This is the default for count_vectorizer. Below, we will create a Pipeline, consisting of Countvectorizer, TfidfTransformer, and LogisticRegression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2fec7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapping = {'neg': 1, 'pos': 0 }\n",
    "\n",
    "cat_labels = list(cat_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0054f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_clf = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range = (1,3),\n",
    "                              decode_error='ignore', \n",
    "                              stop_words='english',)),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b28736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = pipe_clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = pipe_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f36c4747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.7576484703059388\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1614f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2effa14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |    0.78   | 0.838  |  0.808   |   3046  |\n",
      "|  neg  |   0.715   | 0.632  |  0.671   |   1955  |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "Important Features:\n",
      " \n",
      "neg:\n",
      "\n",
      "\t-2.1687\tnope           \t\t6.2222\tfuck           \n",
      "\t-2.0416\tfavorite       \t\t6.0295\tass            \n",
      "\t-1.5882\tidk            \t\t5.7562\tgay            \n",
      "\t-1.5112\tim             \t\t5.7298\temo            \n",
      "\t-1.4658\treason         \t\t5.5438\tbitch          \n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n",
    "\n",
    "\n",
    "vectorizer = pipe_clf.named_steps['vect']\n",
    "\n",
    "clf = pipe_clf.named_steps['clf']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "imp_features = get_most_informative_features(clf, vectorizer,cat_labels, 10)\n",
    "\n",
    "print('Important Features:\\n', imp_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e1966b",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0c53491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.8816\n",
      "Test 0.78624275144971\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_Trainvec, y_train)\n",
    "nb_score = nb.score(X_Trainvec, y_train)\n",
    "print(\"Train\", nb_score)\n",
    "nb_score = nb.score(X_Testvec, y_test)\n",
    "print( \"Test\",nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2abe1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb = nb.predict(X_Testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "be1bd329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      3099\n",
      "           1       0.71      0.73      0.72      1902\n",
      "\n",
      "    accuracy                           0.79      5001\n",
      "   macro avg       0.77      0.78      0.77      5001\n",
      "weighted avg       0.79      0.79      0.79      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_nb,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401fe3b4",
   "metadata": {},
   "source": [
    "### Perform Naive Bayes Classifier from trained data to reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fccede1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66     12542\n",
      "           1       0.31      0.59      0.41      4303\n",
      "\n",
      "    accuracy                           0.57     16845\n",
      "   macro avg       0.56      0.57      0.53     16845\n",
      "weighted avg       0.68      0.57      0.59     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_nb_red = nb.predict(X_Testvec_red)\n",
    "print(classification_report(pred_nb_red,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f563b52",
   "metadata": {},
   "source": [
    "**Pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4d415128",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range = (1,3),\n",
    "                              decode_error='ignore', \n",
    "                              stop_words='english', )),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('mnb', MultinomialNB()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6ec19fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mnb = pipe_mnb.fit(X_train, y_train)\n",
    "\n",
    "predictions_mnb = pipe_mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "361af24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.7812437512497501\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "33f1f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions_mnb, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "de32072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |   0.775   | 0.903  |  0.834   |   3046  |\n",
      "|  neg  |   0.797   | 0.591  |  0.679   |   1955  |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "Important Features:\n",
      " \n",
      "neg:\n",
      "\n",
      "\t-10.2595\t000            \t\t-4.8113\thate           \n",
      "\t-10.2595\t0007           \t\t-4.8267\tfuck           \n",
      "\t-10.2595\t00pm           \t\t-5.0345\tdamn           \n",
      "\t-10.2595\t04             \t\t-5.0985\tsucks          \n",
      "\t-10.2595\t05             \t\t-5.1205\tass            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n",
    "\n",
    "\n",
    "vectorizer = pipe_mnb.named_steps['vect']\n",
    "\n",
    "mnb = pipe_mnb.named_steps['mnb']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "imp_features = get_most_informative_features(mnb, vectorizer,cat_labels, 10)\n",
    "\n",
    "print('Important Features:\\n', imp_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de68d5",
   "metadata": {},
   "source": [
    "### MNB with Grid Search on reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b5b0175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = LemmaTokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "43083309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(decode_error='ignore', stop_words='english')),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('mnb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(decode_error='ignore', stop_words='english'),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'mnb': MultinomialNB(),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'ignore',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': 'english',\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'mnb__alpha': 1.0,\n",
       " 'mnb__class_prior': None,\n",
       " 'mnb__fit_prior': True}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_param_grid = { \n",
    "    'mnb__alpha': (1, 0.1, 0.01, 0.001,0.0001, 0.00001)\n",
    "}\n",
    "\n",
    "pipe_mnb_red = Pipeline(\n",
    "    [('vect', CountVectorizer(  ngram_range = (1,3),\n",
    "                                decode_error='ignore', \n",
    "                                stop_words='english',)),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('mnb', MultinomialNB())\n",
    "     ])\n",
    "\n",
    "pipe_mnb_red.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e64d037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'mnb__alpha': 0.0001} best score:  0.8230666666666666\n"
     ]
    }
   ],
   "source": [
    "# pipe_mnb\n",
    "\n",
    "CV_mnp_reddit= GridSearchCV(pipe_mnb_red,\n",
    "                            mnb_param_grid, cv= 25)\n",
    "\n",
    "CV_mnp_reddit.fit(X_train,y_train)\n",
    "\n",
    "print(\"best params: \",CV_mnp_reddit.best_params_, \"best score: \", \n",
    "      CV_mnp_reddit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "74d2132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (With Grid search): 0.5392104482042149\n"
     ]
    }
   ],
   "source": [
    "best = CV_mnp_reddit.best_estimator_\n",
    "\n",
    "\n",
    "predictions_mnb_red_gscv = best.predict(X_test_red)\n",
    "print('accuracy (With Grid search):', \n",
    "      accuracy_score(y_test_red, predictions_mnb_red_gscv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fcae5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.54      0.66     14078\n",
      "           1       0.19      0.56      0.28      2767\n",
      "\n",
      "    accuracy                           0.54     16845\n",
      "   macro avg       0.53      0.55      0.47     16845\n",
      "weighted avg       0.75      0.54      0.60     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_mnb_red_gscv,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7caca",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5cff1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9955333333333334\n",
      "Test 0.8504299140171966\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_Trainvec, y_train)\n",
    "dt_score = dt.score(X_Trainvec, y_train)\n",
    "print(\"Train\", dt_score)\n",
    "dt_score = dt.score(X_Testvec, y_test)\n",
    "print( \"Test\",dt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "091d872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = dt.predict(X_Testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6aa9d494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.86      2494\n",
      "           1       0.95      0.74      0.83      2507\n",
      "\n",
      "    accuracy                           0.85      5001\n",
      "   macro avg       0.87      0.85      0.85      5001\n",
      "weighted avg       0.87      0.85      0.85      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_dt,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc265b1e",
   "metadata": {},
   "source": [
    "### Perform Decision Tree Classifier from trained data to reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be37fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.69     14927\n",
      "           1       0.17      0.70      0.27      1918\n",
      "\n",
      "    accuracy                           0.57     16845\n",
      "   macro avg       0.55      0.63      0.48     16845\n",
      "weighted avg       0.85      0.57      0.64     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dt_red = dt.predict(X_Testvec_red)\n",
    "print(classification_report(pred_dt_red,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210af522",
   "metadata": {},
   "source": [
    "**Pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "de6b750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range = (1,3),\n",
    "                              decode_error='ignore', \n",
    "                              stop_words='english', )),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('dt', DecisionTreeClassifier()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e6fa1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dt = pipe_dt.fit(X_train, y_train)\n",
    "\n",
    "predictions_dt = pipe_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "696df89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.8498300339932013\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a460065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions_dt, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c567ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |   0.961   | 0.786  |  0.865   |   3046  |\n",
      "|  neg  |    0.74   |  0.95  |  0.832   |   1955  |\n",
      "+-------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c46b3",
   "metadata": {},
   "source": [
    "### Decision tree pipeline with Grid Search on reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8a488ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect', CountVectorizer(stop_words='english')),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('dt', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(stop_words='english'),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'dt': DecisionTreeClassifier(),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': 'english',\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'dt__ccp_alpha': 0.0,\n",
       " 'dt__class_weight': None,\n",
       " 'dt__criterion': 'gini',\n",
       " 'dt__max_depth': None,\n",
       " 'dt__max_features': None,\n",
       " 'dt__max_leaf_nodes': None,\n",
       " 'dt__min_impurity_decrease': 0.0,\n",
       " 'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 2,\n",
       " 'dt__min_weight_fraction_leaf': 0.0,\n",
       " 'dt__random_state': None,\n",
       " 'dt__splitter': 'best'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = [i for i in range(40)]\n",
    "dt_param_grid = { \n",
    "    'vect__ngram_range': [(1, 3)],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [2,4,6,8,10,12],\n",
    "    'dt__min_samples_split': [2, 3, 4],\n",
    "    'dt__max_leaf_nodes': nodes,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "pipe_dt_red = Pipeline(\n",
    "    [('vect', CountVectorizer( ngram_range = (1,3),\n",
    "                              stop_words='english', )),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('dt', DecisionTreeClassifier()),\n",
    "     \n",
    "     ])\n",
    "\n",
    "pipe_dt_red.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fb6064b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "360 fits failed out of a total of 7200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 942, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 316, in fit\n",
      "    max_leaf_nodes\n",
      "ValueError: max_leaf_nodes 0 must be either None or larger than 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 942, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 316, in fit\n",
      "    max_leaf_nodes\n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.65966667 0.65973333 0.65966667]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'dt__criterion': 'gini', 'dt__max_depth': 6, 'dt__max_leaf_nodes': 24, 'dt__min_samples_split': 3, 'vect__ngram_range': (1, 3)} best score:  0.6938000000000001\n"
     ]
    }
   ],
   "source": [
    "CV_dt_reddit= GridSearchCV(pipe_dt_red,\n",
    "                            dt_param_grid, cv= 5)\n",
    "\n",
    "CV_dt_reddit.fit(X_train,y_train)\n",
    "\n",
    "print(\"best params: \",CV_dt_reddit.best_params_, \"best score: \", \n",
    "      CV_dt_reddit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5074e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy ( Grid Search): 0.6760647870425914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      3776\n",
      "           1       0.40      0.64      0.49      1225\n",
      "\n",
      "    accuracy                           0.68      5001\n",
      "   macro avg       0.63      0.66      0.63      5001\n",
      "weighted avg       0.74      0.68      0.70      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best_dt = CV_dt_reddit.best_estimator_\n",
    "\n",
    "# OR recreate the best estimator if you run out of memory like me\n",
    "\n",
    "pipe_dt_red_best = Pipeline(\n",
    "    [('vect', CountVectorizer( ngram_range= (1, 3),\n",
    "                              stop_words='english' )),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('dt', DecisionTreeClassifier(criterion= 'gini',max_depth= 6,\n",
    "      max_leaf_nodes= 24,min_samples_split=3,))\n",
    "     \n",
    "     ])\n",
    "\n",
    "pipe_dt_red_best.fit(X_train,y_train)\n",
    "predictions_dt_red = pipe_dt_red_best.predict(X_test)\n",
    "print('accuracy ( Grid Search):', accuracy_score(y_test, predictions_dt_red))\n",
    "\n",
    "print(classification_report(predictions_dt_red,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cc3f5348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         i'm from spain, i hate this shit\n",
       "1        the funny thing spanish nobility basically inv...\n",
       "2        my mother spanish thankfully taught siblings i...\n",
       "3        you mean country created spanish language lang...\n",
       "4        that's thing ... odds poster isn't aware spain...\n",
       "                               ...                        \n",
       "16840                                                 i :p\n",
       "16841    [image]\\n\\n[mobile]\\n\\n**title:** words small ...\n",
       "16842    it strawman, you're taking argument there, fig...\n",
       "16843    yes no.  i think certain restraint public bit ...\n",
       "16844    sure, freedom expression public place taken ov...\n",
       "Name: comments, Length: 16845, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case we want to transform the reddit test data \n",
    "\n",
    "# pipe_dt_red_tr = Pipeline(\n",
    "#     [('vect_tr', CountVectorizer(  ngram_range = (1,3),\n",
    "#                               stop_words='english', )),\n",
    "#      ('tfidf_tr', TfidfTransformer()), \n",
    "#      ])\n",
    "# pipe_dt_red_tr.fit(X_test_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a3828b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (With Grid search): 0.5557138616800238\n"
     ]
    }
   ],
   "source": [
    "pred_dt_GSCV_red = pipe_dt_red_best.predict(X_test_red)\n",
    "\n",
    "print('accuracy (With Grid search):', \n",
    "      accuracy_score(y_test_red, pred_dt_GSCV_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2bc5a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.54      0.69     15636\n",
      "           1       0.11      0.74      0.19      1209\n",
      "\n",
      "    accuracy                           0.56     16845\n",
      "   macro avg       0.54      0.64      0.44     16845\n",
      "weighted avg       0.90      0.56      0.66     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_dt_GSCV_red,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a334a63",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e589c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9955333333333334\n",
      "Test 0.9194161167766447\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_Trainvec, y_train)\n",
    "rf_score = rf.score(X_Trainvec, y_train)\n",
    "print(\"Train\", rf_score)\n",
    "rf_score = rf.score(X_Testvec, y_test)\n",
    "print( \"Test\",rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "299c8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_Testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "531d3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      2903\n",
      "           1       0.93      0.87      0.90      2098\n",
      "\n",
      "    accuracy                           0.92      5001\n",
      "   macro avg       0.92      0.91      0.92      5001\n",
      "weighted avg       0.92      0.92      0.92      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_rf,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec25cf",
   "metadata": {},
   "source": [
    "### Perform Random Forest Classifier from trained data to reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c47ef634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.70     15718\n",
      "           1       0.11      0.81      0.20      1127\n",
      "\n",
      "    accuracy                           0.56     16845\n",
      "   macro avg       0.54      0.68      0.45     16845\n",
      "weighted avg       0.92      0.56      0.67     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_rf_red = rf.predict(X_Testvec_red)\n",
    "print(classification_report(pred_rf_red,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9779e8",
   "metadata": {},
   "source": [
    "**Pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "344993a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(\n",
    "    [('vect', CountVectorizer(decode_error='ignore', \n",
    "                              stop_words='english', )),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('rf', RandomForestClassifier()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03132b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rf = pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "predictions_rf = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fafe6ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.9024195160967806\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab490e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions_rf, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f186001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |   0.958   | 0.878  |  0.916   |   3046  |\n",
      "|  neg  |   0.832   | 0.941  |  0.883   |   1955  |\n",
      "+-------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee5f49",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aaf9a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.959\n",
      "Test 0.8754249150169966\n"
     ]
    }
   ],
   "source": [
    "sv = SVC()\n",
    "sv.fit(X_Trainvec, y_train)\n",
    "sv_score = sv.score(X_Trainvec, y_train)\n",
    "print(\"Train\", sv_score)\n",
    "sv_score = sv.score(X_Testvec, y_test)\n",
    "print( \"Test\",sv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "665be777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sv = sv.predict(X_Testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d99f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2927\n",
      "           1       0.87      0.82      0.85      2074\n",
      "\n",
      "    accuracy                           0.88      5001\n",
      "   macro avg       0.87      0.87      0.87      5001\n",
      "weighted avg       0.88      0.88      0.87      5001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_sv,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef76e80",
   "metadata": {},
   "source": [
    "### Perform SVM from trained data to reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60cb16ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.54      0.70     16022\n",
      "           1       0.09      0.85      0.16       823\n",
      "\n",
      "    accuracy                           0.55     16845\n",
      "   macro avg       0.54      0.69      0.43     16845\n",
      "weighted avg       0.94      0.55      0.67     16845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sv_red = sv.predict(X_Testvec_red)\n",
    "print(classification_report(pred_sv_red,y_test_red))\n",
    "# for C < 1 => negative f1-score : 0.08 - 0.15, positive: 0.69 - 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e5be5",
   "metadata": {},
   "source": [
    "**Pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "875652ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sv = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('sv', SVC()),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68191458",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rf = pipe_sv.fit(X_train, y_train)\n",
    "\n",
    "predictions_sv = pipe_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b202da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.7886989553656221\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions_sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaafe80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions_sv, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3de139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |    0.78   | 0.827  |  0.802   |   2187  |\n",
      "|  neg  |    0.8    | 0.748  |  0.773   |   2025  |\n",
      "+-------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375022c3",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8370e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.6088666666666667\n",
      "Test 0.6090781843631273\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(solver=\"lbfgs\",activation=\"relu\", alpha=1e-4, hidden_layer_sizes=(4, 4), random_state=11)\n",
    "nn.fit(X_Trainvec, y_train)\n",
    "nn_score = nn.score(X_Trainvec, y_train)\n",
    "print(\"Train\", nn_score)\n",
    "nn_score = nn.score(X_Testvec, y_test)4\n",
    "print( \"Test\",nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "28e13593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nn = nn.predict(X_Testvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58da7274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int(value.(set(y_test) - set(pred_nn)))\n",
    "len(y_test)\n",
    "len(pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2aee1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76      5001\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61      5001\n",
      "   macro avg       0.50      0.30      0.38      5001\n",
      "weighted avg       1.00      0.61      0.76      5001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_nn,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56541b2",
   "metadata": {},
   "source": [
    "### Perform MLP from trained data to reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4ae123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.69     16845\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52     16845\n",
      "   macro avg       0.50      0.26      0.34     16845\n",
      "weighted avg       1.00      0.52      0.69     16845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Program Files\\Anaconda3\\envs\\tf_env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_nn_red = nn.predict(X_Testvec_red)\n",
    "print(classification_report(pred_nn_red,y_test_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8343988",
   "metadata": {},
   "source": [
    "**Pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1abb15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nn = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('nn', MLPClassifier(solver=\"lbfgs\",activation=\"relu\", alpha=1e-4, hidden_layer_sizes=(4, 4), random_state=11)),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7eb522dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nn = pipe_nn.fit(X_train, y_train)\n",
    "\n",
    "predictions_nn = pipe_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1d5be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy (simple): 0.7908357075023742\n"
     ]
    }
   ],
   "source": [
    "print('accuracy (simple):', accuracy_score(y_test, predictions_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b47da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_info = metrics.classification_report(y_test, predictions_nn, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5201ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+----------+---------+\n",
      "| Label | Precision | Recall | f1-score | support |\n",
      "+-------+-----------+--------+----------+---------+\n",
      "|  pos  |   0.811   | 0.779  |  0.795   |   2187  |\n",
      "|  neg  |   0.771   | 0.803  |  0.787   |   2025  |\n",
      "+-------+-----------+--------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "tab = PrettyTable(['Label', 'Precision', 'Recall', 'f1-score', 'support'])\n",
    "\n",
    "\n",
    "for key, value in measures_info.items():\n",
    "    if key.isdigit():\n",
    "        label = get_key_categories(cat_mapping, key)\n",
    "        tab.add_row([label, round(value['precision'],3), round(value['recall'],3), round(value['f1-score'],3), value['support']])\n",
    "    else:\n",
    "        pass\n",
    "      \n",
    "\n",
    "print(tab)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
